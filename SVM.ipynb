{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e77018-eb69-40f5-98d4-c35ad3a3cbd6",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "This section imports all the required libraries for data manipulation, visualization, preprocessing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a3f1b2-9116-4822-90fe-844c62c8ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3d8ff-ba44-4259-884b-59b74bdc4aff",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset\n",
    "This section loads the dataset from a URL and performs exploratory data analysis such as summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3929a0ad-9b05-41e5-a953-2889d6a44f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = r\"C:\\Users\\Sonymaths\\Downloads\\archive\\WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c50cc8-e4ed-4be1-8632-c8c1fd6ee47f",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This section preprocesses the data by defining pipelines for numerical and categorical data, applying transformations, splitting the data into training and testing sets, and addressing class imbalance using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896e721f-f807-4ef1-9677-6d188a53d69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\New folder\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).drop(columns=['Attrition']).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing pipeline for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse=False))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply the transformations\n",
    "X = df.drop(columns=['Attrition'])\n",
    "y = df['Attrition'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Address class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2d83c-abf6-4326-81b1-033f96f637e7",
   "metadata": {},
   "source": [
    "## Model  Training and Hyperparameter Tuning\n",
    "This section trains a Support Vector Machine (SVM) classifier and tunes its hyperparameters using grid search with cross-validation. It defines the SVM model, specifies the hyperparameter grid, performs grid search with cross-validation, identifies the best SVM model, and prints its best parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4151cec0-700d-4c9a-aec0-0ebf626ec69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Best Params: {'C': 100, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Define the SVM model\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid_svm = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=strat_kfold, scoring='f1', return_train_score=True)\n",
    "grid_search_svm.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best SVM model\n",
    "best_svm = grid_search_svm.best_estimator_\n",
    "print(f\"Support Vector Machine Best Params: {grid_search_svm.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe35c28-61eb-45eb-9731-89e7f0c520cf",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "This section evaluates the performance of the best Support Vector Machine (SVM) model obtained after hyperparameter tuning. It predicts the test data, calculates various evaluation metrics such as accuracy, precision, recall, F1 score, and ROC-AUC score based on the predictions. Then, it prints these metrics to assess the model's performance. Additionally, it displays the classification report and confusion matrix to provide a detailed analysis of the model's performance across different classes and confusion between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b541a7b9-53cc-4b40-a023-283d653fdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8673\n",
      "Precision: 0.5000\n",
      "Recall: 0.3590\n",
      "F1 Score: 0.4179\n",
      "ROC-AUC Score: 0.7811\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       255\n",
      "           1       0.50      0.36      0.42        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.70      0.65      0.67       294\n",
      "weighted avg       0.85      0.87      0.86       294\n",
      "\n",
      "Confusion Matrix:\n",
      "[[241  14]\n",
      " [ 25  14]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best SVM model\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Display classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844a766f-9702-4eaa-a220-2efbde178bfa",
   "metadata": {},
   "source": [
    "## Cross Validaion Evaluation \n",
    "This section performs cross-validation to evaluate the performance of the best Support Vector Machine (SVM) model obtained after hyperparameter tuning. It calculates the F1 scores for each fold of the stratified k-fold cross-validation and prints these scores to assess the model's performance across different folds. Additionally, it prints the mean and standard deviation of the cross-validation F1 scores to provide insights into the model's average performance and its variability across different folds of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3cf024-0e6f-4725-974f-8c29a7293408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.95121951 0.9408867  0.96517413 0.94348894 0.97270471]\n",
      "Mean CV F1 Score: 0.9547\n",
      "Standard Deviation of CV F1 Scores: 0.0123\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation scores\n",
    "cv_results = cross_val_score(best_svm, X_train_res, y_train_res, cv=strat_kfold, scoring='f1')\n",
    "\n",
    "print(f\"Cross-Validation F1 Scores: {cv_results}\")\n",
    "print(f\"Mean CV F1 Score: {cv_results.mean():.4f}\")\n",
    "print(f\"Standard Deviation of CV F1 Scores: {cv_results.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
